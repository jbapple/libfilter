% VLDB journal - https://www.springer.com/journal/778/submission-guidelines Fee for open access $2780 https://www.springer.com/journal/778/open-access-publishing#Fees%20and%20Funding
% JEA - journal https://dl.acm.org/journal/jea/instructions-for-authors Fee for open access $1700 or $1300 https://www.acm.org/publications/openaccess#h-open-access-pricing
% TKDE - Journal https://www.computer.org/csdl/journal/tk can't figure out if open access available with fee

% ALENEX - August 11  submission, October 31 notification, https://www.siam.org/conferences/cm/submissions-and-deadlines/alenex22-submissions-deadlines, Alexandria, January 9-10
% SIGMOD - September 15th, feedback November 1-8, accept reject December 6th https://2022.sigmod.org/calls_papers_important_dates.shtml, Philly, June 12-17th

% SODA - Passed, no 2023 date yet https://www.siam.org/conferences/cm/conference/soda22
% USENIX ATC - Passed, no 2022 website yet https://www.usenix.org/conferences/byname/131
% KDD - Passed, no 2022 website yet https://kdd.org/conferences
% ICDE - Passed, no 2023 website yet https://icde2022.ieeecomputer.my/research-track/
% VLDB - Passed, no 2022 website yet, but rolling submissions from the 20th to the 1st of each month http://vldb.org/2021/?important-dates
% SEA -Passed, no 2022 date yet

% PVLDB - same conference as VLDB, submit here first http://vldb.org/pvldb/vol15-submission/


% \documentclass[letterpaper]{article}
\documentclass[manuscript,screen,review]{acmart}

\pdfoutput=1

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{color}
\usepackage{graphicx}
%\PassOptionsToPackage{hyphens}{url}\usepackage[pdftitle={Stretching your data with taffy filters}]
%\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
\usepackage{microtype}
% TODO: fix underscores
%\usepackage[strings]{underscore}
%\usepackage{doi}
%\usepackage{nicefrac}
\usepackage{listings}
%\usepackage{todonotes}
\usepackage{epigraph}
%\usepackage{ifthen}
%% \usepackage{tikz}
%% \usetikzlibrary{arrows.meta}
%\usepackage[export]{adjustbox}
%\usepackage{framed}


\newtheorem{theorem}{Theorem}

\lstset{
%    frame=tb, % draw a frame at the top and bottom of the code block
%    tabsize=2, % tab space width
%    showstringspaces=false, % don't mark spaces in strings
  numbers=left, % display line numbers on the left
%    commentstyle=\color{green}, % comment color
%    keywordstyle=\color{blue}, % keyword color
%    stringstyle=\color{red}, % string color
  basicstyle=\small\ttfamily,
  basewidth = {.48em}
}

\DeclareMathOperator{\adj}{adj}

%\renewcommand\UrlFont{\color{blue}\rmfamily}

%% \newcommand{\reals}{\mathbb{R}}
%% \newcommand{\rats}{\mathbb{Q}}
%% \newcommand{\nats}{\mathbb{N}}
\newcommand{\ints}{\mathbb{Z}}
%% \newcommand{\cplx}{\mathbb{C}}
\newcommand{\defeq}{\;\genfrac{}{}{0pt}{2}{\text{def}}{=}\;}
\newcommand{\dotcup}{\ensuremath{\mathaccent\cdot\cup}}

%\pagestyle{empty}

% https://tex.stackexchange.com/questions/171803/change-font-size-of-the-verbatim-environment
% \newcommand{\verbatimfont}[1]{\renewcommand{\verbatim@font}{\ttfamily#1}}

%% \usepackage{etoolbox}
%% \makeatletter
%% \patchcmd{\@verbatim}
%%   {\verbatim@font}
%%   {\verbatim@font\small}
%%   {}{}
%% \makeatother


\begin{document}


\title{Stretching Your Data With Taffy Filters}
\author{Jim Apple}
\email{jbapple@apache.org}
\orcid{0000-0002-8685-9451}

\begin{abstract}
\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10002951.10002952.10002971.10003450.10010829</concept_id>
       <concept_desc>Information systems~Point lookups</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003809.10010055.10010056</concept_id>
       <concept_desc>Theory of computation~Bloom filters and hashing</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Point lookups}
\ccsdesc[500]{Theory of computation~Bloom filters and hashing}

\keywords{bloom filters, dictionaries, hash tables}

%\thispagestyle{empty}


\begin{abstract}
Popular approximate membership query structures such as Bloom filters, counting Bloom filters, cuckoo filters, and quotient filters must be created with a given size when built with the expectation that the number of items inserted will not exceed some previously specified cardinality.
In fact, Pagh, Segev, and Wieder (FOCS '13) show that the minimum size of a filter must be super-linear in $n$ if such a structure can increase in capacity as new elements are added.
This paper explores three instantiations of such a structure and compares them experimentally.
The resulting code is available for general use.\footnote{\url{https://github.com/jbapple/libfilter}}
\epigraph{If you can look into the seeds of time, and say which grain will grow and which will not, speak then unto me.}{Macbeth}
\end{abstract}




\maketitle


\section{Introduction}

While there are many filter structures that support approximate membership queries on sets with a given maximum size, the question of extensible (or {\itshape extendable} or {\itshape incremental} or {\itshape growable}) filters is little studied.
The classic answer is to create a sequence of Bloom filters, possibly of increasing sizes and/or lower false positive probabilities.
Inserts occur on the last filter to be created and lookups must search each filter.

Even when this keeps the false positive rate low, lookup times balloon from constant to logarithmic or even linear.~\cite{psw,logarithm,consistent-cuckoo} %The Dynamic Cuckoo Filter
Additionally, the space usage can grow up to $\Omega(n \lg n)$, at which point a traditional hash table would do the same work in the same space.
Later authors consider cuckoo filters in which, when the filter grows, the size of the fingerprint shrinks, thereby increasing the false positive probability.~\cite{logarithm,morton-journal,vacuum,rsqf}

In \cite{psw}, the authors introduce a structure that performs lookups in $O(1)$ time while still allowing the structure to grow and keep a low false positive rate (not exceeding a threshold specified when the structure was created) all while using no more than $O(\lg \lg n + \lg (1/\varepsilon))$ words of space per element.
Section~\ref{tcf} presents {\em taffy cuckoo filters} (``TCFs''), a practical instantiation of this model, an outstanding challenge from \cite{psw}.

TCFs, because of their resize operation, are sometimes only 50\% full.
%As noted in \cite{dysect}, dictionaries like \cite{succinct} do not directly address the problem of using low space when the dictionary is not near the maximum space it will need.
%For example, as a set grows from size $n$ to $2n$ in increments of one, the dictionary in \cite{succinct} will reconstruct the entire dictionary at least once.
%Furthermore, if each reconstruction increases the capacity from $m$ to $(1 + \delta)m$, $1/\lg(1+\delta)$ rebuilds will occur.
%Finally, non-power-of-two sizes pose challenges for quotienting, a technique needed to reduce the space usage by up to one bit per element.~\cite{change-your-base, cleary-quotient}
Section~\ref{mtcf} presents {\em minimal taffy cuckoo filters} (``MTCFs'') based on~\cite{dysect}.
MTCFs re-allocate and refill the table only once for each time the table doubles in size, but do so without increasing the capacity and space usage of the table beyond a small percentage over the size of the data contained within.

Section~\ref{pbf} presents {\em taffy block filters}, a variation of the ``warm-up'' structure from \cite{psw}.
These are filters based on a SIMD implementation of block Bloom filters. \cite{block-bloom}.

Section \ref{eval} also describes experimental performance results on all taffy filters.

% TODO: block filters with 16 hash functions - when useful?

\section{Prior work}

\subsection{Filters that can grow}

\cite{psw} describes two constructions to support extensible filters.
The first, is implemented as a series of Bloom filters.
Common similar constructions use geometrically decreasing false positive probabilities in each subsequent filter in order to bound the total false positive rate.
That is, they create a sequence of Bloom filters with the following pairs for the false positive probability and expected number of distinct values:

\[
\langle \varepsilon / 2, 2 \rangle,
 \langle \varepsilon / 4, 4 \rangle,
 \langle \varepsilon / 8, 8 \rangle,
 \langle \varepsilon / 16, 16 \rangle,
 \ldots
\]

This leads to a storage footprint of more than $(\lg n + \lg (1/\epsilon)) / \ln 2$ bits per element and a query time of $\lg^2 n + \lg (n/\varepsilon)$.
\cite{psw} reduce this to $\lg n$ by using a dictionary like \cite{succinct} that has $O(1)$ query time per filter.
They also reduce the space usage to  by using the sequence $\langle \varepsilon / i^2,  2^i \rangle$, rather than  $\langle \varepsilon / 2^i,  2^i \rangle$.

\cite{psw} also present a filter with the same space usage but $O(1)$ query time.
This filter maintains a dictionary from $n$ to a pair of values, one of bit length $\lg n + \lg (1/\varepsilon)$ and one of bit length {\itshape up to} $\lg \lg N$, where $N$ will be the largest size of the data structure.
After every $2^i$ insertions, a new dictionary is created mapping from $2n$ to a pair of values, one of bit length $1 + \lg n + \lg (1/\varepsilon)$ and one of bit length up to $\lg \lg N$.
The extra bit needed in the first value of the co-domain is acquired by stealing a high order bit from the second value.
This shrinks the second value by one bit.
If there is nothing to be stolen, two elements of the co-domain are generated, one with a new 0 appended, one with a 1; both are inserted into the dictionary.

\subsection{Succinct dictionaries}

Dictionaries of size $n$ from $U$ to $V$ can be stored in $n (\lg U + \lg V - \lg n + 1)$ bits.
The oldest example of this is \cite{knuth}; the technique is generally called quotienting. \cite{quotient-filter}
Taffy filters are based on quotienting in cuckoo hash tables, as used in \cite{backyard}.
There, two arrays are established to hold $\lg U + \lg V - \lg n + O(1)$ bits.
A key is stored by using one of two permutations, one each per array.
A value of length $\lg U + \lg V$ is reduced to one of $\lg U + \lg V - \lg n + O(1)$ by storing each value in the slot corresponding to the first $\lg n - O(1)$ bits of its permuted value.
This number of bits can then be omitted from the stored value.
When a value needs to be kicked between tables, as in inserts to a cuckoo hash table, the un-permuted value is reconstructed using the slot index and the stored value.
It can then be permuted by the other permutation and inserted in the other array.
For details see Section \ref{tcf} and Figure \ref{tcf-insert}, line 21.

\subsection{Compact extensible dictionaries}

Hash tables used to accommodate sets with unknown size in advance typically do so by doubling in capacity.
This means that at least 50\% of the space goes unused.
Constructions like \cite{succinct} are able to mitigate this, but they are largely theoretical.
Instead, \cite{dysect} uses the cuckoo hashing kick operation to incrementally resize a hash table.
First, the table is broken up into equal sized sub-arrays that can be resized independently.
When the table gets close to full, one of the sub-arrays is doubled in size.
Eventually all will have been doubled in size, thereby causing the whole table to have doubled in size.

\section{Taffy cuckoo filters}
\label{tcf}
Taffy cuckoo filters (``TCFs'') are approximate membership query structures that offer the following operations:

\begin{itemize}
\item {\bf Create} initializes an empty filter with the given size
  %and false positive probability, and expected {\em growth factor}.
  %A growth factor is the maximum number of doublings the structure must be able to undergo while maintaining the given false positive probability.
\item {\bf Insert} adds a key to the filter.
  This takes $O(1)$ expected time.
  It can fail when the filter is nearly full.
\item {\bf Lookup} takes a key and returns \verb|True| if the key is in the structure and \verb|False| with probability $1-\varepsilon$ if the key is not in the structure.
  It takes $O(1)$ worst-case time
\item {\bf Upsize} doubles the capacity of the filter in $\Theta(n)$ time.
\item {\bf Union} adds the items from another filter of size $m$ in $O(m)$ time.
%% \item {\bf Intersection} Produces a new filter with only the items in both input filters, taking O(min(m,n)) time
\end{itemize}

We use quotienting cuckoo tables (as in backyard cuckoo hashing~\cite{backyard}) to store the data in a taffy cuckoo filter.
The quotienting table uses permutation hash functions to transform the input key into two different hash values such that either can be used to reconstruct a portion of the original key.

The top $\lg n - O(1)$ bits are omitted from the stored hash values, since these are implicitly stored in the location of the key within the table.
In this way, data can be moved from one sub-table to the other via key reconstruction, even without storing the key explicitly.

An element consists of two groups of bits: one of size 10, and the other of size up to 5.
The former is called the fingerprint and the latter is called the tail.
A bucket consists of four (possibly empty) slots, each of which can hold one element.
A side consists of $2^k$ buckets for some $k$ as well as a permutation on $\ints_2^{k+10}$. %\footnote{$\ints_2^m$ and $\ints_{2^m}$.}
A TCF consists of two sides and one hash function that produces a 64-bit key.
The two sides have the same number of buckets but different permutations.

A lookup begins by hashing a key with the TCF's hash function.
Then the lookup operation does the following:

\begin{enumerate}
\item Applies a permutation to the most-significant $k+10$ bits in the key. (Figure \ref{tcf-lookup}, line 14)
\item Reserves the next 5 bits of the key; this will be the key's tail.
\item Using the most-significant $k$ bits in the result, selects a bucket.
(The remaining 10 bits in the permuted value are the fingerprint.)
\item Checks to see if any slot contains an element with an identical fingerprint.
If so, checks if the element's tail is a prefix of the key's tail.
If yes, returns \verb|True|.
Otherwise, returns \verb|False|.
\end{enumerate}

\begin{figure}

\begin{lstlisting}[escapeinside={`}{`}]
Element := {fingerprint: `$\ints_2^{10}$`, tail: `$\dotcup_{i \le 5} \ints_2^i$`}
Slot := Element`$_\bot$`
Bucket := Slot[4]
Side(k) := {Bucket[2`$^k$`], Permutation: `$S_{2^{k+10}}$`}
TCF(U, k) := {Side(k)[2], HashFunction: `$U \to \ints_2^{64}$`}
\end{lstlisting}
\caption{\protect
  The types of a TCF.
  $S_i$ is the symmetric group on $\ints_i$.
  \texttt{T}$_\bot$ means the type \texttt{T} extended with the element $\bot$, indicating ``null'' or ``empty''.
  %As above, pseudocode will not make a distinction between $\ints_2^i$ and $\ints_{2^i}$.
  \texttt{T[n]} denotes an array of $n$ values of type $T$.
  $A \dotcup B$ represents a tagged disjoint union of $A$ and $B$; even if $A \subseteq B$, $A \dotcup B \ne B$.
  Structs are denoted by curly brackets \{\}, and members of structs can be referenced by their name or by their type.
  For instance, if \texttt{s} is a \texttt{Side(k)}, then \texttt{s.Bucket} and \texttt{s.Permutation} are both meaningful expressions.
}

\end{figure}

%TODO: endianness problems pervade the pseudocode?

\begin{figure}

\begin{lstlisting}[escapeinside={`}{`}]
LookupBucket(fingerprint, tail, bucket) {
  for (element : bucket) {
    if (element.fingerprint == fingerprint
        && element.tail IsPrefixOf tail) {
      return True
    }
  }
  return False
}

Lookup(input: U, tcf: TCF(U, k)) {
  hashed := tcf.HashFunction(input)
  for (side : tcf.Side[0], tcf.Side[1]) {
    permuted := side.Permutation(hashed[0, k+10))
    bucket := side.Bucket[permuted[0, k)]
    if LookupBucket(permuted[k, k+10), hashed[k+10, k+15), bucket) {
      return True
    }
  }
  return False
}
\end{lstlisting}
\caption{\label{tcf-lookup}
Pseudocode for the lookup operation on TCFs.
\texttt{S[a, b)} denotes the bits in $S$ starting at location $a$ and continuing through $b-1$.
}

\end{figure}

The insert operation first searches for the key, and, if found, returns.
Otherwise, insert places the key's fingerprint and tail in an empty slot, if one is found.
If none is found, insert selects an occupied slot from the bucket to {\em kick}: the element in this slot will be moved to the other side. (Figure \ref{tcf-insert}, line 18)

The kick operation first reconstructs the high order $k + 10$ bits of the key by concatenating the $k$ bits of the bucket index and the $10$ bits of the fingerprint, then applying that side's permutation in reverse to the value. (Figure \ref{tcf-insert}, line 23)
Using the same tail (this does not get permuted), the kick operation then recursively inserts the data into the opposite side using the insert algorithm described above.

\begin{figure}

\begin{lstlisting}[escapeinside={`}{`}]
InsertBucket(fingerprint, tail, bucket) {
  new_element := {fingerprint := fingerprint, tail: tail}
  for(slot : bucket) {
    if (slot == `$\bot$`) {
      slot := new_element
      return `$\bot$`
    }
  }
  swap(new_element, RandomSlotIn(bucket))
  return new_element
}

InsertSide(tcf: TCF(U,k), side: `$\ints_2$`, hashed: `$\ints_2^{k+10}$`, tail: `$\dotcup_{i \le 5} \ints_2^i$`) {
  permuted := side.Permutation(hashed)
  bucket := side.Bucket[permuted[0, k)]
  slot = InsertBucket(permuted[k, k+10), tail, bucket)
  if (slot == `$\bot$`) return
  Kick(tcf, side, permuted[0, k), slot)
}

Kick(tcf: TCF(U,k), side: `$\ints_2$`, bucket_index: `$\ints_{2^k}$`, element) {
  permuted := Concat(bucket_index, element.fingerprint)
  hashed := tcf[side].Permutation`$^\texttt{-1}$`(permuted)
  InsertSide(tcf, 1 - side, hashed, element.tail)
}

InsertTCF(input: U, tcf: TCF(U, k)) {
  if (Lookup(input, tcf)) return
  hashed := tcf.HashFunction(input)
  InsertSide(tcf, 0, hashed[0, k+10), hashed[k+10, k+15))
}
\end{lstlisting}
\caption{\label{tcf-insert}
Pseudocode for the insert operation on TCFs}
\end{figure}

The upsize operation begins by creating a new TCF.
To transfer the data, it uses a modified version of the kick algorithm; it needs an alteration, because the number of buckets is now $2^{k+1}$.
To produce a key with that many bits, upsize first reconstructs the $k+10$ bits of the key that were used to construct the bucket index and fingerprint.
Then a bit is ``stolen'' from the tail and appended onto the end of the key.
Since the tail was taken unaltered from the key, this gives $k+11$ bits of the original key.
The new tail is now decreased in size by one.
The key and the new tail of it can now be inserted into one of the sides of the new TCF as described above. (Figure \ref{tcf-upsize}, line 17)

This works as long as the tail has positive length.
If the tail has length zero, there is nothing to steal from.
Instead, two candidate keys are created from the reverse-permuted $k+10$ bits by appending a zero and a one.
It's indeterminate which one of these was in the original key, so both are inserted.
\cite{psw} show that the fpp is less than $2^{-8}$, although in TCFs the actual value will be smaller, since the tail is checked as well.

\begin{figure}

\begin{lstlisting}[escapeinside={`}{`}]
Steal(head, tail) {
  if (|tail| > 0) {
    return Concat(head, tail[0]), tail[1, |tail|)
  }
  return Concat(head, 0), Concat(head, 1)
}

Upsize(tcf: TCF(U, k)) {
  result := new TCF(U, k + 1)
  for (side : tcf) {
    for (bucket_index : `$\ints_{2^k}$`) {
      for (element : side.Bucket[bucket_index]) {
        permuted := Concat(bucket_index, element.fingerprint)
        hashed := side.Permutation`$^\texttt{-1}$`(permuted)
        if (|tail| > 0) {
          (head, tail) := Steal(head, tail)
          InsertSide(result, 0, head, tail)
        } else {
          for (longhead : Steal(head, tail)) {
            InsertSide(result, 0, longhead, tail)
          }
        }
      }
    }
  }
  tcf = result
}
\end{lstlisting}
\caption{\label{tcf-upsize}
Pseudocode for the upsize operation on TCFs}

\end{figure}

%% TCFs support a union operation as well, which operates by iterating over the smaller TCF and inserting into the larger.
%% The iteration is able to partially reconstruct the original hashed key (before permutations) using the same method as in upsize in Figure \ref{tcf-upsize}, lines 10-14.
%% Although this does not allow the insert method to be used directly, a variation on insert (Figure \ref{tcf-insert}, line 13-19) can insert a pair of a prefix of a hashed value and a tail.
%% Like upsize, union then steals bits from the tail, except union keeps stealing until the hash value is as long as needed to fit with the insert of the TCF being uniond into.
%% This results in a false positive probability that is the sum of the false positive probabilities of the two input TCFs.

%% TODO:  union benchmarks

%% TODO: union proofs

%% % TODO: intersection

%% \begin{figure}
%% \begin{lstlisting}[escapeinside={`}{`}]
%% InsertUnion(tcf: TCF(U,k), side: `$\ints_2$`, hashed: `$\ints_2^{j+10}$`, tail: `$\dotcup_{i \le 5} \ints_2^i$`) {
%%   if (j == k) return InsertSide(tcf, side, hashed, tail)
%%   if (|tail| > 0) {
%%     (head, tail) := Steal(hashed, tail)
%%     return InsertUnion(tcf, side, head, tail)
%%   }
%%   for (longhead : Steal(hashed, tail))
%%     InsertUnion(tcf, side, longhead, tail)
%%   }
%% }

%% Union(from: TCF(U, k), to: TCF(U, j)) {
%%   if (k > j) return Union(to, from)
%%   for (side : {0, 1}) {
%%     for (bucket_index : `$\ints_{2^k}$`) {
%%       for (element : from.Sides[side].Bucket[bucket_index]) {
%%         permuted := Concat(bucket_index, element.fingerprint)
%%         hashed := from[side].Permutation`$^\texttt{-1}$`(permuted);
%%         InsertUnion(to, side, hashed, element.tail)
%%       }
%%     }
%%   }
%% }
%% \end{lstlisting}
%% \caption{
%% Pseudocode for the union opeation on TCFs.
%% The two input TCFs must have the same hash function.
%% }
%% \end{figure}


% \subsection{Space and false positive analysis}



%% In \cite{psw}, the dictionary is broken up into subsequences of size $2^i$.
%% Each subsequence $S_i$ contains the inserted keys with insertion order number in $[2^i, 2^{i+1})$.
%% Only when transitioning subsequences is the steal operation performed.
%% However, in PCFs, transitions happen when the dictionary is near full.
%% This does not necessarily correspond to the sequences.
%% Firstly, the $i$th dictionary cannot hold $2^i$ keys, just $\alpha 2^i$, where $\alpha$ si the ``fill factor''.
%% Second, the dictionary is sized according to the number of entries, while the structure in \cite{psw} is sized according to the number of insertions.
%% These differ, as the number of entries for a sequence grows as the sequence lengthens as a result of the steals against an empty tail.

%% The false positive probability depends on the number of elements with different tail lengths.
%% Specifically, in a dictionary with $n$ elements where $p(i)$ is the number of elements with tail of length $i$, the false positive probability is less than

%% \[
%% 8 n^{-1} \sum_{i \le 7} 2^{-i-8}p(i)
%% \]

%% \[
%% 2^{-5} n^{-1} \sum_{i \le 7} 2^{-i}p(i)
%% \]

%% In any insertion sequence $I$, let $\alpha_I$ be the smallest number such that a dictionary with $\alpha_I x$ entries and capacity for $x$ entries is upsized.



%% \begin{theorem}
%%   $p(i)$
%% \end{theorem}~\begin{proof}
%% Assuming the dictionary starts with both sides having Bucket arrays of size 1, and thus having an element capacity of 8, the first $8 \alpha$ elements are inserted before any upsizing and therefore have tails of the full length, 7.
%% In this first phase, a candidate gets compared to at most $8 \alpha$ elements and has a $2^{-15}$ chance of collision with each, for a false positive probability (``fpp'') of less than $2^{-12}$.
%% Once the table has resized to having capacity 16, at most 8 of the slots are filles with tails of length 6.
%% The addition of at most 8 more items of length 7 makes

%% %% \[
%% %% p(i) =
%% %% \begin{cases}
%% %% 8 & i = 6\\
%% %% 8 & i = 7\\
%% %% 0 & \text{otherwise}
%% %% \end{cases}
%% %% \]

%% %% and thus the fpp is less than $8 \cdot 16^{-1} (2^{-14}\cdot 8 + 2^{-15}\cdot 8) = 2^{-12} + 2^{-13}$.
%% %% Repeating, we get

%% %% \[
%% %% p(i) =
%% %% \begin{cases}
%% %% 8 & i = 5\\
%% %% 8 & i = 6\\
%% %% 16 & i = 7\\
%% %% 0 & \text{otherwise}
%% %% \end{cases}
%% %% \]

%% %% and thus the fpp is less than $8 \cdot 32^{-1} (2^{-13}\cdot 8 + 2^{-14}\cdot 8 + 2^{-15}\cdot 16) = 2^{-12} + 2^{-13} + 2^{-13}$.

%% %% \[
%% %% p(i) =
%% %% \begin{cases}
%% %% 8 & i = 4\\
%% %% 8 & i = 5\\
%% %% 16 & i = 6\\
%% %% 32 & i = 7\\
%% %% 0 & \text{otherwise}
%% %% \end{cases}
%% %% \]

%% %% and thus the fpp is $8 \cdot 64^{-1} (2^{-12}\cdot 8 + 2^{-13}\cdot 8 + 2^{-14}\cdot 16 + 2^{-15}\cdot 32) = 2^{-12} + 2^{-13} + 2^{-13} + 2^{-13}$.

%% %% This pattern repeats until and including

%% %% \[
%% %% p(i) =
%% %% \begin{cases}
%% %% 8 & i = 0\\
%% %% 2^{2+i} & \text{otherwise}
%% %% \end{cases}
%% %% \]

%% %% when $n = 2^{10}$ after inserting $2^10$.

%% %% so the fpp is less than $2^{-12} + 6 \cdot 2^{-13}$

%% %% After that, the next $p(i)$ is

%% %% \[
%% %% p(i) =
%% %% \begin{cases}
%% %% 3 \cdot 2^3 & i = 0\\
%% %% 2^{10} - 8 & i = 7 \\
%% %% 2^{3+i} & \text{otherwise}
%% %% \end{cases}
%% %% \]

%% %% \[
%% %% p(i) =
%% %% \begin{cases}
%% %% 4 \cdot 2^4 & i = 0\\
%% %% 2^{10} - 2\cdot2^2 & i = 6 \\
%% %% 2^{11} - 3\cdot 2^3 & i = 7 \\
%% %% 2^{4+i} & \text{otherwise}
%% %% \end{cases}
%% %% \]

%% %% \[
%% %% p(i) =
%% %% \begin{cases}
%% %% 9 \cdot 2^9 & i = 0\\
%% %% 2^{10} - 2 \cdot 2^2 & i = 1 \\
%% %% 2^{11} - 3 \cdot 2^3 & i = 2 \\
%% %% 2^{12} - 4 \cdot 2^4 & i = 3 \\
%% %% 2^{13} - 5 \cdot 2^5 & i = 4 \\
%% %% 2^{14} - 6 \cdot 2^6 & i = 5 \\
%% %% 2^{15} - 7 \cdot 2^7 & i = 6 \\
%% %% 2^{16} - 8 \cdot 2^8 & i = 7 \\
%% %% \end{cases}
%% %% \]

%% %% \[
%% %% p(i) =
%% %% \begin{cases}
%% %% a  & i = 0\\
%% %% b & i = 1 \\
%% %% c & i = 2 \\
%% %% d & i = 3 \\
%% %% e & i = 4 \\
%% %% f & i = 5 \\
%% %% g & i = 6 \\
%% %% h & i = 7
%% %% \end{cases}
%% %% \]

%% $p$ with total size $m = 2^j$

%% changes to

%% \[
%% p(i) =
%% \begin{cases}
%% p(1) + 2p(0) & i = 0\\
%% p(2) & i = 1 \\
%% p(3) & i = 2 \\
%% p(4) & i = 3 \\
%% p(5) & i = 4 \\
%% p(6) & i = 5 \\
%% p(7) & i = 6 \\
%% 2^j - p(0) & i = 7 \\
%% \end{cases}
%% \]

%% with total size $2^{j+1}$.

%% The fpp changes from

%% \[
%% \varepsilon 8 \cdot 2^{-j} \left(\sum p(i) 2^{-i}\right)
%% \]

%% to

%% \[
%% 2^{-j + 2} \left(p(1) + 2p(0) + (2^j - p(0))2^{-7} + \sum_{i = 1}^{i < 7} p(i) 2^{-i+1}\right)
%% \]

%% if $p(0) < 3 \cdot 2^{j-2}$, then this is at most

%% \[
%% 2^{-j + 2} \left(p(1) + 2 \cdot  3 \cdot 2^{j-2} + (2^j -  3 \cdot 2^{j-2})2^{-7} + \sum_{i = 1}^{i < 7} p(i) 2^{-i+1}\right)
%% \]

%% \[
%% 2^{-j + 2} \left(p(1) + 3 \cdot 2^{j-1} + (2^{j-2})2^{-7} + \sum_{i = 1}^{i < 7} p(i) 2^{-i+1}\right)
%% \]

%% \[
%% 2^{-j+2} \left(p(1) + 3 \cdot 2^{j-1} + (2^{j-2})2^{-7} + \sum_{i = 1}^{i < 7} p(i) 2^{-i+1}\right)
%% \]

%% \[
%% \varepsilon (2^{-j+2}p(1) + 3 \cdot 2^{1} + 2^{-7} + \sum_{i = 1}^{i < 7} p(i) 2^{-i-j+3}
%% \]

%% \[
%% \varepsilon (2^{-j+2}p(1) + 12 + 2^{-7} + \sum_{i = 1}^{i < 7} p(i) 2^{-i-j+3}
%% \]

%% Everything except 12 is vanishing, so 

%% \[
%% \begin{cases}
%% 2^{10} - 2 \cdot 2^2 & i = 1 \\
%% 2^{11} - 3 \cdot 2^3 & i = 2 \\
%% 2^{12} - 4 \cdot 2^4 & i = 3 \\
%% 2^{13} - 5 \cdot 2^5 & i = 4 \\
%% 2^{14} - 6 \cdot 2^6 & i = 5 \\
%% 2^{15} - 7 \cdot 2^7 & i = 6 \\
%% 2^{16} - 8 \cdot 2^8 & i = 7 \\
%% \end{cases}
%% \]


%% \[
%% p(i) =
%% \begin{cases}
%%  -2 \cdot 2^2 + 10 \cdot 2^{10} & i = 0\\
%% 2^{11} - 3 \cdot 2^3 & i = 1 \\
%% 2^{12} - 4 \cdot 2^4 & i = 2 \\
%% 2^{13} - 5 \cdot 2^5 & i = 3 \\
%% 2^{14} - 6 \cdot 2^6 & i = 4 \\
%% 2^{15} - 7 \cdot 2^7 & i = 5 \\
%% 2^{16} - 8 \cdot 2^8 & i = 6 \\
%% 2^{17} - 9 \cdot 2^9 & i = 7 \\
%% \end{cases}
%% \]

%% \[
%% p(i) =
%% \begin{cases}
%% - 5 \cdot 2^3 + 11 \cdot 2^{11} & i = 0\\
%% 2^{12} - 4 \cdot 2^4 & i = 1 \\
%% 2^{13} - 5 \cdot 2^5 & i = 2 \\
%% 2^{14} - 6 \cdot 2^6 & i = 3 \\
%% 2^{15} - 7 \cdot 2^7 & i = 4 \\
%% 2^{16} - 8 \cdot 2^8 & i = 5 \\
%% 2^{17} - 9 \cdot 2^9 & i = 6 \\
%% 2^{17} - 9 \cdot 2^9 & i = 6 \\
%% \end{cases}
%% \]

%% with $n = 2^{11} - 2^4 + 3 \cdot ^3$ after inserting $2^11$

%% and then

%% \[
%% p(i) =
%% \begin{cases}
%% 4 \cdot 2^4 & i = 0\\
%% 2^{4+i} & \text{otherwise}
%% \end{cases}
%% \]

%% with $n = 2^{12} - 2^5 + 4 \cdot 2^4$


%% following the pattern

%% \[
%% p(i) =
%% \begin{cases}
%% j \cdot 2^j & i = 0\\
%% 2^{j+i} & \text{otherwise}
%% \end{cases}
%% \]

%% when $n = j \cdot 2^j - 2^{j+1} + 2^{8+j}$ after inserting

%% In this case, the false positive probability is 

%% \[
%% 2^{-5} \cdot (j \cdot 2^j - 2^{j+1} + 2^{8+j})^{-1}(j \cdot 2^j + 2^{-1}2^{j+1} + 2^{-2}2^{j+2} \dots)
%% \]

%% \[
%% 2^{-5} \cdot (j \cdot 2^j - 2^{j+1} + 2^{8+j})^{-1}(j \cdot 2^j + 7\cdot2^j)
%% \]

%% \[
%% 2^{-5} \cdot (2^j(j - 2 + 2^8))^{-1}2^j(j + 7)
%% \]

%% \[
%% 2^{-5} (j - 2 + 2^8)^{-1}(j + 7)
%% \]

%% \[
%% \frac{j+7}{2^5 (j - 2 + 2^8)}
%% \]

%% \end{proof}

%% That is only approximated in PCFs, as the 

%% The calculations of how many slots the accumulation of these doublings produces is the key calculation in the space consumption analysis in~\cite{psw}.
%% That is crucial as well for the false positive rate
%% For the concrete setting here, if the dictionary starts with $k = 0$ (each side having size 1 bucket), then after $m$ upsizes, if $m < 7$, $2^{m+2}(1 - \delta)$ keys have been inserted and the same number are in the dictionary.
%% Half of the tails have length seven, a quarter have length six, and so on.
%% The false positive probability is $2^{m+2}(1 - \delta) \cdot 2^{-m-8}(m \cdot 2^{-8}) = m(1-\delta)2^{-14}$, which is between $6.1E-5$ and $4.2E-4$.
%% TODO: experimentally different. Make graph.
%% %% check to see if the tail in that slot is a prefix of the 

%% %% To look up a key

%% %% Plastic cuckoo filters are based on this filter, but additionally add a value to each key.
%% %% The value is the next $\lg d$ bits of the key, where $d$ is the growth factor.



%% %% Plastic cuckoo filters are based on a type of bloomier filter.
%% %% A bloomier filter is an AMQ supporting lookups, not just membership queries.
%% %% Given a domain and range $D$ and $R$ where $D \subset U$ and $M$ is a map from $D$ to $R$, a query for $x$ in a bloomier filter for $M$ returns $M(x)$ if $x \in D$ and $\bot$ with probability $1-\varepsilon$ when $x \in U \backslash D$, and otherwise returns an arbitrary value in $R$.

%% %% Next we will form a quotienting cuckoo map.
%% %% A quotienting cuckoo map has a domain of $\ints_d$ and a range of $\ints_r$.
%% %% A standard cuckoo map would use $d + r$ bits per unit of capacity.
%% %% A quotienting cuckoo table uses $d + r + \lg b -  \lg m $ where $m$ is the capacity of the table and $b$ is the size of the bucket.


%% %% In an elastic filter, the permuted key has length $\lg \nicefrac{1}{\varepsilon} + \lg m - \lg b$ while the range consists of all sequences of bits of length less than $\lg\lg \nicefrac{U}{n} + O(1)$.
%% %% When the table is nearly full, meaning that further additions would likely fail, the size is doubled.
%% %% This increases the size of the unstored bits by 1, so the number of stored bits would be smaller, as well.
%% %% Instead of letting that happen, a bit is ``stolen'' from the range of sequences of bits.

%% %% This shortens the value in the range, but the range stays the same.
%% %% If there are no bits to steal becuase the value is the empty string, {\em two} new values are generated to insert into the new, larger table: one with a one appended to the stored bits, one with a zero.
%% %% This follows directly from \cite{psw}.

\section{Minimal taffy cuckoo filters}
\label{mtcf}

The previous structure suffers from a step-function space usage:
at each point, the structure has a size which is a power of two, sometimes allocating much more space than will be needed.
To address this, this section describes a similar structure using DySECT to reduce the space usage to only what is needed.~\cite{dysect}

A DySECT table consists of some number of {\em levels}.
As the table gets more and more full, the table grows by doubling the size of one of its levels.

In a minimal taffy cuckoo filter (``MTCF''), each element has a fingerprint of size 8 or 9 and a tail of size up to 5.
A bucket consists of four (possibly empty) slots, each of which can hold one element.
A level consists of two tables of the same size, each with $2^k$ buckets for some $k$.
The table consists of four permutations, one hash function, $32$ levels, and one cursor pointing to some index in the set of levels.
The maximum and minimum $k$ across all levels differ by at most 1.
Levels at location less than the cursor have the larger size.
If all levels have the same size, the cursor must be 0.
See Figure \ref{mtcf-diagram}.

The permutations are grouped by side, two for each.
The permutations are on values with length $k + 13$ and $k + 14$, where $2^k$ is the size of the smallest table, measured in buckets.

\begin{figure}

\begin{lstlisting}[escapeinside={`}{`}]
MElement := {fingerprint: `$\ints_2^8 \dotcup \ints_2^9$`, tail: `$\dotcup_{i \le 5} \ints_2^i$`}
MSlot := MElement`$_\bot$`
MBucket := MSlot[4]
Level(k) := MBucket[2][2`$^k$`] `$\dotcup$` MBucket[2][2`$^{k+1}$`]
Permutation(k) := `$S_{2^{k+13}} \times S_{2^{k+14}}$`
MTCF(U, k) := {cursor: `$\ints_{32}$`,
               Level(k)[32],
               Permutation(k)[2],
               HashFunction: `$U \to \ints_2^{64}$`}

\end{lstlisting}
\caption{The types of an MTCF.
``$\times$'' means Cartesian product.
}

\end{figure}


\begin{figure}
  \includegraphics{mpcf-diagram}
\caption{\label{mtcf-diagram}
A diagram of an MTCF.
In this example, $k = 2$, so the larger levels have $2^{k+1} = 8$ buckets on each side, while the smaller levels have four.
In the first bucket of side 0 of the 32nd level, the last three slots are empty.
If the entry were from one of the larger levels above the cursor, then the fingerprint would have to be from $\ints_2^8$.
}

\end{figure}

If there are larger and smaller levels, then every element in the larger levels has a fingerprint of size 8, not 9.
This is because the implicitly-stored part of the key is one-bit longer in the larger levels.

In an MTCF, upsize only increases the size of one of the levels, not the whole structure.
As a result, the capacity of the filter tracks more closely the number of entries in the table.

A lookup operation in an MTCF first applies each of the four permutations to the hashed key.
For the permutations on $k + 14$ bits, the first five bits indicate the level, the next $k$ or $k+1$ indicate the bucket, and the remaining 8 or 9 bits are the fingerprint.
Lookup proceeds as it does in the TCF case, by checking if fingerprints match and if the stored tail is a prefix of the tail of the key being looked up.
For the permutations on $k + 13$ bits, the first five bits again indicate the level.
If the level has tables with $2^{k+1}$ buckets, the permuted key is not used for lookup; to do otherwise would leave only $k+13 - 5 - (k+1) = 7$ bits for the fingerprint, which is not possible.
That key is simply skipped and the lookup continues with the next key. %See Figure \ref{mtcf-insert}.
Otherwise, the level has tables with $2^k$ buckets, and we can proceed as in the $k+14$ case.

%% Upsize only increases the size of one level.
%% After 31 upsizes, the next one makes all of the levels the same size.
%% At that point, two new permutations must be initialized to handle new longer key prefixes.

During a kick operation, an element may move between levels with differently-sized arrays of buckets.
This poses no problem when the fingerprint has size 9, but when the fingerprint has size 8 and the level moved {\em from} has a bucket array of size $2^k$ and the level moved {\em to} has a bucket array of size $2^{k+1}$,  there are not enough bits in the fingerprint.
As above, we steal bits from the tail, and, as above, if there are no bits to steal, two new key prefixes are created and inserted, as one of them must be the prefix of the original key.

Pseudocode for lookup, insert, and upsize are available in Appendix \ref{mtcf-appendix}.

\section{Taffy block filters}
\label{pbf}

The ``warm-up'' structure in \cite{psw} consists of a set of filters of decreasing false positive probabilities but exponentially increasing size (in terms of the number of distinct elements).
The $i$th filter is initialized to have false positive probability
\[
\frac{6 \varepsilon}  {i^2 \pi^2}
\]
for a total false positive probability of at most $\varepsilon$.
In order to keep the query time down to $\lg n$, rather than $\lg^2n + \lg n \lg (1/\varepsilon)$, dictionary-based filters such as cuckoo filters, rather than Bloom filters, are used.
However, split block Bloom filters can perform 5x or more better than cuckoo filters. \cite{cuckoo-filter-github}

A taffy block filter (``TBF'') uses this variant of block bloom filters. \cite{block-bloom, ultra-fast}
A single 256-bit block is used for inserting or looking up each item, and the filter is composed of many such blocks, laid out in an array.
Within each block, a ``split'' Bloom filter sets one bit in each of eight 32-bit lanes, rather than eight bits in one 256-bit range.~\cite{split-bloom}
(Exactly eight hash functions are used in order to fit cleanly into SIMD lanes.)
On insert of lookup, the key is hashed eight times to a range of $[0,32)$ using SIMD instructions and multiply-shift universal hashing: $h_{s_i}(x) = \lfloor(s_i \cdot x) / 2^{27}\rfloor$, where $s_i$ are odd seeds.~\cite{multiply-shift}
One bit is set (on insert) or examined (on lookup) in each lane.

%% TBFs cannot perform the union operation without significant increases in false positive probability.
%% For instance, in two split block Bloom filters of size $m$ where each level has $\delta m$ its bits set, the expected number of bits set in their union is $(2 \delta - \delta^2) m$.
%% Each of the input filters has false positive probability $\delta ^ 8$, while the output filter has false positive probability of nearly $2^8$ times that.

\section{Evaluation}
\label{eval}

In each graph, TBFs are configured for a maximum fpp of 0.1\%.
%In case the insert operation fails, it calls Upsize until a place can be found for the element.
All taffy filters are configured with an initial capacity of 1, however the MTCF has a minimum size of 2 bytes/entry $\cdot$ 32 levels $\cdot$ 2 sides/level $\cdot$ 1 entry / side = 128 bytes.
All experiments were performed on an Intel i7-7800X with 96GB of memory and SMT turned on.

For performance testing, we equip both TCFs and MTCFs with variable sized stashes. \cite{stash}
We set both filters to upsize when they are 90\% full or their stashes have size greater than 4.

For comparison, the graphs also include a cuckoo filter and a split-block bloom filter, each sized to hold 100 million elements with an fpp of 0.1\%.

\subsection{Space}

A filter with a false positive probability of $\varepsilon$ must take up at least $\lg (1/\varepsilon)$ bits per element.
Practical filters use more space.
For instance, Bloom filters use $\lg (1/\varepsilon)/\ln 2$ bits per element, which is about $1.44 \lg (1/\varepsilon)$.
Cuckoo filters and quotient filters use $(\lg (1/\varepsilon) + d) / \alpha$ where $d$ is between 2 and 3, and $\alpha$ is the fill factor, between 80\% - 99\%. \cite{cuckoo,quotient-filter,vector-quotient}
Static filters that do not support insert -- such as the ribbon filter -- can use nearly optimal space. \cite{ribbon}

However, \cite{psw} showed that filters that can grow, like taffy filters can, must use at least $\lg (1/\varepsilon) + \Omega(\lg \lg n)$ bits per element.
Figures \ref{bits-per-item} and \ref{ideal-bits-per-item} show the actual bits per element and $\lg (1/\varepsilon)$, respectively.

Cuckoo filters cannot grow (without changing the number of bits per slot and doubling the false positive rate.
As such, cuckoo filters are only visible over 10 million elements on the space graph, since their bits per key starts out at over 1.2 billion bits per.

% TODO: graph different MTCF variants based on level size, fingerprint size

% TODO: graph fill factor

% TODO: freeze/thaw operations with ribbon filters

% TODO: compare standard bloom filters, block bloom filters, filters with exponentially decreasing fpp, and cuckoo filters


\begin{figure}

  \includegraphics[width=\textwidth]{bits-per-item}
  \caption{  \label{bits-per-item}
Number of bits (per element) each filter type needs.}
\end{figure}

\begin{figure}
  \includegraphics[width=\textwidth]{ideal-bits-per-item}
  \caption{  \label{ideal-bits-per-item}
This figure shows $\varepsilon$, the false positive probability.}
\end{figure}


%% \begin{figure}
%%   \includegraphics[width=\textwidth]{deficiency}
%%   \caption{
%%     There is a lower bound on the amount of space that must be used to form an approximate membership query structure with a given false positive rate: $\lg \nicefrac{1}{\varepsilon}$ bits per element.
%%     Any additional space is, in a sense, ``wasted''.
%%     In another sense, this overstates the waste, as the best dynamic structures, like Bloom filters and semi-sorted cuckoo filters, do not achieve the lower bound.
%%     Lower is better.
%%   }
%% 
%% \end{figure}

%% \begin{figure}
%%   \includegraphics[width=\textwidth]{insert-deficiency}
%%   \caption{
%%     Comparing both the wasted space of each filter type with the absent lookup performance.
%%     Lower left is better.
%%   }
%% \end{figure}

\begin{figure}
  \includegraphics[width=\textwidth]{space}
  \caption{
    The amount of space used by each filter at the given number of keys inserted.
  }
\end{figure}

\subsection{Time}

Figures \ref{insert-time}, \ref{lookup-present}, \ref{lookup-absent} show the performance of the taffy filters.
TBFs are the fastest, with the exception of absent lookups for filters with over a million elements, where TCFs and cuckoo filters are faster, needing only two cache misses to check for a key, while TBFs need to check 27 block filters.


\begin{figure}
  \includegraphics[width=\textwidth]{insert}
  \caption{
    \label{insert-time}
    Insert times for filters.
    %% TODO: the dip is an artifact; redo with more samples and longer time between timer start \& stop.
  }
\end{figure}

\begin{figure}
  \includegraphics[width=\textwidth]{lookup-present}
  \caption{
    \label{lookup-present}
    Lookup times for filters when the key is present.
  }
\end{figure}

\begin{figure}
  \includegraphics[width=\textwidth]{lookup-absent}
  \caption{
    \label{lookup-absent}
    Lookup times for filters when the key is absent.
  }
\end{figure}

\subsection{Discussion}

The MTCF offers lower space than the other two taffy filters, but its performance is substantially worse.
It has significant insertion time increases when it is hard to find a kick sequence; in this case consecutive insert operations may call Upsize, causing a spike in the graph.
This cyclic behavior was noted in the original DySECT paper. \cite{dysect}
%This behavior is also seen in the TCF, though less severely.
% Performance for lookup is also cyclic as the fill factor and size of the stashes grow and shrink.
Additionally, when the cursor is close to 32, the performance of lookup improves as the four potential locations to look for a key are more frequently reduced to two, since the shorter permuted keys are no longer long enough for most of the levels in the structure.

TBFs, which have an $\Theta(\lg n)$ lookup cost, come out ahead of the other types of taffy filters in both insert and lookup costs except when over a million elements are stored.
Split-block Bloom filters and cuckoo filters are still attractive choices when the size of the set to be approximated is known in advance.



% TODO: show different level counts and how that decreases the spikiness?

% TODO: what is the fpp of the dictionary, analytically

% TODO: explain permutation swapping

% TODO: explain combining tails

% TODO: show that longer fingerprints lead to higher fill factors

% TODO: Show how much time is spent in Upsize

% TODO: show how stash limits lead to higher insert times and lower lookup times

% TODO: show that the size of the dictionary stays limited, as in \cite{psw}

\section{Future work}

The stash limitations for the TCF and MTCF are very low - tuned for a linear search.
It is not necessary they be unstructured - giving structure to the stash, as in \cite{backyard}, could allow the stash to grow and the fill factor to go higher without needing to upsize.

There is a fourth structure supporting sets of unknown sizes described in \cite{unknown-prefix}.
This structure is mostly theoretical and depends onn a certain type of prefix search with large embedded constants.
A practical version of this may be possible to build.

For the TCF, alternate quotienting dictionaries, including \cite{raman-practical} or \cite{quotient-filter}, could potentially improve performance.

Finally, testing taffy filters in various applications requiring the use of extensible approximate membership query structure would be of interest.

\bibliographystyle{ACM-Reference-Format}
\bibliography{taffy}

\appendix
\section{MTCF pseudocode}
\label{mtcf-appendix}

\begin{figure}[!htbp]

\begin{lstlisting}[escapeinside={`}{`}]
LookupSide(mtcf: MTCF(U, k), side: `$\ints_2$`, hashed: `$\ints_2^{64}$`) {
  permuted := mtcf.Permutation[side](hashed[0, k+13))
  level_number := permuted[0, 5)
  if (level_number `$\ge$` mtcf.cursor) {
    bucket := mtcf.Level[level_number][permuted[5, k + 5)]
    if (LookupBucket(permuted[k+5, k+13),
                     hashed[k+13, k+18), bucket)) {
      return True
    }
  }
  permuted = mtcf.Permutation[side](hashed[0, k+14))
  level_number = permuted[0, 5)
  middle := (level_number `$\ge$` mtcf.cursor) then k+5 else k+6
  bucket := mtcf.Level[level_number][permuted[5, middle)]
  return LookupBucket(permuted[middle, k+14),
                      hashed[k+14, k+19), bucket)
}

MLookup(mtcf: TCF(U, k), key: U) {
  hashed := mtcf.HashFunction(key)
  for (side : {0, 1}) {
    if (LookupSide(mtcf, side, hashed)) return True
  }
  return False
}
\end{lstlisting}
\caption{The lookup operation in an MTCF.}

\end{figure}

\begin{figure}

\begin{lstlisting}[escapeinside={`}{`}]
MInsertSide(mtcf: MTCF(U, k), side: `$\ints_{2}$`, level_number: `$\ints_{32}$`,
            bucket_number: `$\ints_{2^k} \dotcup \ints_{2^{k+1}}$`, fingerprint `$\ints_2^8 \dotcup \ints_2^9$`,
            tail: `$\sum_{i \le 5}\ints_2^i$`,) {
  bucket := mtcf.Level[level_number][side][bucket_number]
  new_slot := InsertBucket(fingerprint, tail, bucket)
  if (new_slot == `$\bot$`) return
  fingerprint = new_slot.fingerprint
  tail = new_slot.tail
  permuted := Concat(level_number, bucket_number, fingerprint)
  hashed := mtcf.Permutation[side]`$^\texttt{-1}$`(permuted)
  permuted = mtcf.Permutation[1 - side](hashed)
  MInsertPermuted(mtcf, side, permuted, tail)
}

MInsertPermuted(mtcf: MTCF(U, k), side: `$\ints_2$`, permuted: `$\ints_2^{k+13} \dotcup \ints_2^{k+14}$`,
                tail: `$\sum_{i \le 5}\ints_2^i$`) {
  level_number := permuted[0, 5)
  if (|permuted| == k + 14) {
    middle := if (level_number `$\ge$` mtcf.cursor) then k+5 else k+6
    MInsertSide(mtcf, 1 - side, level_number, permuted[5, middle),
                permuted[middle, k+14), tail)
    return
  }
  if (level_number `$\ge$` mtcf.cursor) {
    permuteds := {permuted}
    middle := k + 5
  } else (|tail| > 0) {
    (permuted, tail) := Steal(permuted, tail)
    permuteds := {permuted}
    middle := k + 6
  } else {
    permuteds := Steal(permuted, tail)
    middle := k + 6
  }
  for (p : permuteds) {
    MInsertSide(mtcf, 1 - side, level_number, p[5, middle),
                p[middle, middle + 8), tail)
  }
}


\end{lstlisting}
\caption{Pseudocode for the insert operation on MTCFs}

\end{figure}


\begin{figure}

\begin{lstlisting}[escapeinside={`}{`}]
InsertMTCF(mtcf: MTCF(U, k), key: U) {
  if (MLookup(mtcf, key)) return
  hashed := mtcf.HashFunction(key)
  permuted := mtcf.Permutation[0](hashed[0, k+14))
  level_number := permuted[0, 5)
  middle := if (level_number `$\ge$` mtcf.cursor) then k+5 else k+6
  bucket_number := permuted[5, middle)
  fingerprint := permuted[middle, k+14)
  tail := hashed[k+14, k+19)
  MInsertSide(mtcf, 0, level_number,  bucket_number, fingerprint,
              tail)
}
\end{lstlisting}
\caption{Pseudocode for the insert operation on MTCFs}

\end{figure}

\begin{figure}
\begin{lstlisting}[escapeinside={`}{`}]
UpsizeMTCF(mtcf: MTCF(U, k)) {
  old := mtcf.Level[mtcf.cursor]
  mtcf.Level[mtcf.cursor] = new Level(2`$^{{k+1}}$`)
  mtcf.cursor = mtcf.cursor + 1
  for (side : {0, 1}) {
    for (bucket_index : `$\ints_{2^k}$`) {
      for (element : old.MBucket[side][bucket_index]) {
        cursor = cursor - 1
        permuted := Concat(cursor, bucket_index, slot.fingerprint)
        hashed := mtcf.Permutation[side]`$^{\texttt{-1}}$`(permuted)
        cursor = cursor + 1
        permuted = mtcf.Permutation[side](hashed)
        MInsertPermuted(permuted, element.tail, side, mtcf)

      }
    }
  }
}
\end{lstlisting}
\caption{Pseudocode for the upsize operation on MTCFs}
\end{figure}

%% \begin{figure}
%% \begin{lstlisting}[escapeinside={`}{`}]
%% MInsertUnion(mtcf: MTCF(U, k), side: `$\ints_2$`, hashed: `$\ints_2^{j+13}\dotcup\ints_2^{j+14}$`,
%%              tail: `$\dotcup_{i \le 5} \ints_2^i$`) {
%%   if (j == k) {
%%     permuted = mtcf.Permutation[side](hashed)
%%     return MInsertPermuted(mtcf, side, permuted, tail)
%%   }
%%   if (|tail| > 0) {
%%     (head, tail) := Steal(hashed, tail)
%%     return MInsertUnion(mtcf, side, head, tail)
%%   }
%%   for (h : Steal(hashed, tail)) {
%%     MInsertUnion(mtcf, side, h, tail)
%%   }
%% }

%% Union(from: MTCF(U, k), to: MTCF(U, j)) {
%%   if (k > j) return Union(to, from)
%%   for (level : `$\ints_32$`)
%%     for (side : {0, 1}) {
%%       for (bucket_index : `$\ints_{2^k}$`) {
%%         for (element : from.Sides[side].Bucket[bucket_index]) {
%%           permuted := Concat(level, bucket_index, element.fingerprint)
%%           hashed := from[side].Permutation`$^\texttt{-1}$`(permuted);
%%           MInsertUnion(to, side, hashed, element.tail)
%%         }
%%       }
%%     }
%%   }
%% }

%% \end{lstlisting}
%% \caption{Pseudocode for the union operation on MTCFs.
%% The input MTCFs must have the same hash function.}
%% \end{figure}

\end{document}

%%  LocalWords:  growable lookups quotienting AMQ Upsize TCF TCF's
%%  LocalWords:  HashFunction LookupBucket IsPrefixOf tcf InsertTCF
%%  LocalWords:  InsertSide InsertBucket RandomSlotIn otherSide TCFs
%%  LocalWords:  Concat upsize doublings DySECT MTCF MSlot MBucket
%%  LocalWords:  upsizes TODO fpp LookupSide mtcf MLookup MInsertSide
%%  LocalWords:  MInsertPermuted permuteds MTCFs InsertMTCF MElement
%%  LocalWords:  UpsizeMTCF TBFs Structs structs SMT Pagh Segev FOCS
%%  LocalWords:  Wieder longhead TBF onn
